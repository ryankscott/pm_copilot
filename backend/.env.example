# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# AI Provider API Keys (optional - configure as needed)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GOOGLE_GENERATIVE_AI_API_KEY=your_google_api_key_here

# Langfuse Configuration
# To use Langfuse for prompt management, you need to set the following environment variables.
# These are used by the backend service to connect to your Langfuse project.
#
# 1. Sign up or log in to your Langfuse account (e.g., at https://cloud.langfuse.com).
# 2. Create a new project in Langfuse.
# 3. In your Langfuse project settings, navigate to "API Keys" to find your keys.
#
# LANGFUSE_BASEURL=https://cloud.langfuse.com # Optional: Defaults to Langfuse Cloud if not set. Use if you have a self-hosted instance.
# LANGFUSE_SECRET_KEY=your_langfuse_secret_key # Required: Your Langfuse project's secret key.
# LANGFUSE_PUBLIC_KEY=your_langfuse_public_key # Required: Your Langfuse project's public key.
#
# After setting these variables in your actual .env file (copied from this example),
# you need to run the prompt migration script once to populate your Langfuse project with the application's prompts:
# From the 'backend' directory, run:
# pnpm exec ts-node ./scripts/migratePromptsToLangfuse.ts
# or (if you add a script to package.json like "migrate-prompts": "ts-node ./scripts/migratePromptsToLangfuse.ts")
# pnpm run migrate-prompts
